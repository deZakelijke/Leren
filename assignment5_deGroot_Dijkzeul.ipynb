{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leren: Programming assignment 5\n",
    "** This assignment can be done in teams of 2 **\n",
    "\n",
    "**Student 1:**  <span style=\"color:red\">de Groot</span> (<span style=\"color:red\">10434410</span>)<br>\n",
    "**Student 2:** <span style=\"color:red\"> Dijkzeul</span> (<span style=\"color:red\">10554386</span>)<br>\n",
    "\n",
    "-----------------------------------\n",
    "You may want to use parts of your code from the previous assignment(s) as a starting point for this assignment. \n",
    "\n",
    "The code you hand-in should follow the structure from this document. Write down your functions in the cells they belong to. Note that the structure corresponds with the structure from the actual programming assignment. Make sure you read this for the full explanation of what is expected of you. \n",
    "\n",
    "**Submission:**\n",
    "\n",
    "* Make sure your code can be run from top to bottom without errors.\n",
    "* Include your data files in the zip file.\n",
    "* Comment your code\n",
    "\n",
    "One way be sure you code can be run without errors is by quiting iPython completely and then restart iPython and run all cells again (you can do this by going to the menu bar above: Cell > Run all). This way you make sure that no old definitions of functions or values of variables are left (that your program might still be using).\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "If you have any questions ask your teaching assistent. We are here for you.\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  55  56  57  58  59  60  61  62  \\\n",
       "0   0   0   1  11  15   8   0   0   0   0 ...   0   0   0   2  15  15   3   0   \n",
       "1   0   0   4  10  11   4   0   0   0   1 ...   0   0   0   5  12  12  12   1   \n",
       "2   0   0   5  14  12   5   0   0   0   0 ...   0   0   0   7  13  16   8   0   \n",
       "3   0   0  14  10   0   0   0   0   0   0 ...   0   0   0  12  16  16  16  16   \n",
       "4   0   0   5  12  10   4   0   0   0   0 ...   0   0   0   8  12  12   4   0   \n",
       "\n",
       "   63  64  \n",
       "0   0   1  \n",
       "1   0   1  \n",
       "2   0   1  \n",
       "3   9   1  \n",
       "4   0   1  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Training = pd.read_csv('digist123-1.csv', sep=\";\", header=None)\n",
    "Test = pd.read_csv('digist123-2.csv', sep=\";\", header=None)\n",
    "\n",
    "# Make the pandas dataframes numpy arrays\n",
    "TrainingNpArray = np.array(Training)\n",
    "TestNpArray = np.array(Test)\n",
    "\n",
    "Training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make dict of all the classes\n",
    "from collections import defaultdict\n",
    "\n",
    "def makeClassDict(nparray):\n",
    "    classDict = defaultdict(list) \n",
    "    for i in nparray:\n",
    "        classDict[i[-1]].append(i[:-1])\n",
    "    return classDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def meanStdAll(classDict):\n",
    "    allClasses = defaultdict(list) \n",
    "    for j in classDict.keys():\n",
    "        for i in zip(*classDict[j]):\n",
    "            if np.std(i) == 0:\n",
    "                allClasses[j].append((np.mean(i),1))\n",
    "            else:\n",
    "                 allClasses[j].append((np.mean(i),np.std(i)))\n",
    "    return allClasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classProbs(allClasses, testData):\n",
    "    probs = {}\n",
    "    for keys in allClasses.keys():\n",
    "        probs[keys] = 1\n",
    "        for idx, i in enumerate(allClasses[keys]):\n",
    "            mean, stdev = i\n",
    "            x = testData[idx]\n",
    "            probs[keys] *= calculateProbability(x, mean, stdev)\n",
    "    return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classDict = makeClassDict(TrainingNpArray)\n",
    "\n",
    "allClasses = meanStdAll(classDict)\n",
    "\n",
    "# print predict(allClasses, TestNpArray[0])\n",
    "\n",
    "\n",
    "def predict(allClasses, vector):\n",
    "    probs = classProbs(allClasses, vector)\n",
    "    best = [0, \"\"]\n",
    "    for i in probs.keys():\n",
    "        if probs[i] > best[0]:\n",
    "            best[0] = probs[i]\n",
    "            best[1] = i\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# testData[:,:-1]\n",
    "def getPredictions(allClasses, testData):\n",
    "    predicts = []\n",
    "    for i in testData:\n",
    "        predicts.append(predict(allClasses, i)[1])\n",
    "    return predicts\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(array1, array2):\n",
    "    same = 0\n",
    "    for i in range(len(array1)):\n",
    "        if array1[i] == array2[i]:\n",
    "            same += 1\n",
    "    return same/float(len(array1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classDict = makeClassDict(TrainingNpArray)\n",
    "\n",
    "allClasses = meanStdAll(classDict)\n",
    "\n",
    "predicts = getPredictions(allClasses, TrainingNpArray[:,:-1])\n",
    "\n",
    "print accuracy(predicts, TrainingNpArray[:,-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b ###\n",
    "\n",
    "The id's of the errors are 108, 144, 245, 279.\n",
    "All these errors are either a 2 or a 3, and are predicted a 2 or a 3.\n",
    "There is a very small difference between the two probabilities. 2 and 3 are very similar numbers and these the wrongly guessed 2 are probably very close to a 3 and vice versa.\n",
    "\n",
    "To overcome this issue it is possible to better train the model. It is also possible to make an check which states that if the difference is so small, that it cannot predict a class with certainty. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n",
      "{1: 2.0149199278462528e-84, 2: 1.961669844242521e-64, 3: 2.1004351443462985e-63}\n",
      "3 2\n",
      "{1: 1.2157039581893253e-167, 2: 1.5132397685230444e-60, 3: 1.95278012433835e-56}\n",
      "2 3\n",
      "{1: 3.8483443456139399e-244, 2: 2.5159492972066129e-78, 3: 2.7040364741429635e-79}\n",
      "2 3\n",
      "{1: 4.0827522383018512e-189, 2: 1.1824230553825879e-63, 3: 2.61713342230593e-64}\n"
     ]
    }
   ],
   "source": [
    "print predicts[108],TrainingNpArray[108][-1]\n",
    "\n",
    "print classProbs(allClasses, TrainingNpArray[108][:-1])\n",
    "\n",
    "\n",
    "print predicts[144],TrainingNpArray[144][-1]\n",
    "\n",
    "print classProbs(allClasses, TrainingNpArray[144][:-1])\n",
    "\n",
    "\n",
    "print predicts[245],TrainingNpArray[245][-1]\n",
    "\n",
    "print classProbs(allClasses, TrainingNpArray[245][:-1])\n",
    "\n",
    "\n",
    "print predicts[279],TrainingNpArray[279][-1]\n",
    "\n",
    "print classProbs(allClasses, TrainingNpArray[279][:-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Code made in week 3 for logisticregression\n",
    "\n",
    "\n",
    "# uses the sigmoid function to calculate the hypothesis\n",
    "def hypothesis(theta, xVector):\n",
    "    return 1.0/(1.0+math.e **(-np.dot(theta,xVector)))\n",
    "\n",
    "# Gradient function for the logistic regression\n",
    "def gradientLog(theta,xMatrix,yVector, thetaIndex):\n",
    "    gradient = (1.0/(1+math.e **(np.dot(theta,xMatrix))))-yVector\n",
    "    gradient = np.dot(gradient,xMatrix[thetaIndex])\n",
    "    return gradient/len(yVector)\n",
    "    \n",
    "# Update the theta vector for logistic regression\n",
    "def updateLog(alpha, theta, xMatrix, yVector, Lambda):\n",
    "    regularizationVector = [1]*len(theta)\n",
    "    tempTheta = [None]*len(theta)\n",
    "    for i in range(len(theta)):\n",
    "        regularizationVector[i] *= Lambda/len(yVector)*theta[i]\n",
    "    regularizationVector[0] = 0\n",
    "    for i in range(len(theta)):\n",
    "        tempTheta[i] = theta[i] - alpha * (gradientLog(theta,xMatrix,yVector,i) + regularizationVector[i])\n",
    "    return tempTheta\n",
    "\n",
    "# Calculate the cost for a logistic regrssion function\n",
    "def costLogFunction(theta, xMatrix, yVector, Lambda):\n",
    "    costSum = 0.0\n",
    "    regularization = 0.0\n",
    "    for i in range(len(yVector)):\n",
    "        if yVector[i]:\n",
    "            costSum += math.log(hypothesis(theta,xMatrix[i]))\n",
    "        else:\n",
    "            costSum += math.log(1-hypothesis(theta,xMatrix[i]))\n",
    "            # dit geeft log(0) omdat hypothesis altijd 1 returned\n",
    "            # dat mag niet\n",
    "    for i in range(1,len(theta)):\n",
    "        regularization += theta[i] **2\n",
    "    return -(costSum/len(yVector) + (2*Lambda/len(yVector)*regularization))\n",
    "    \n",
    "# split y and multiply theta when multi-class classifying\n",
    "def splitClasses(theta, yVector):\n",
    "    classes = list(set(yVector))\n",
    "    if len(classes) <=2 and 0 in classes:\n",
    "        return theta, yVector\n",
    "    else:\n",
    "        # split y in het aantal klasses\n",
    "        yMatrix = np.zeros((len(yVector),len(classes)))\n",
    "        thetaMatrix = np.zeros((len(classes),len(theta)))\n",
    "        for i in range(len(classes)):\n",
    "            for j in range(len(yVector)):\n",
    "                if yVector[j] == classes[i]:\n",
    "                    yMatrix[j][i] = 1\n",
    "                else:\n",
    "                    yMatrix[j][i] = 0\n",
    "            thetaMatrix[i] = theta\n",
    "        yMatrix = yMatrix.T\n",
    "        return thetaMatrix, yMatrix\n",
    "            \n",
    "def logreg(Digits, Lambda):\n",
    "\n",
    "    alpha = 0.00001\n",
    "    iterations = 120\n",
    "    # Echt geen idee welke waarde Lambda moet hebben. Het werkt nu nog steeds dus maybe is het goed?\n",
    "    yVector = Digits[Digits.columns[-1]]\n",
    "    xMatrix = np.ones((Digits.columns[-1]+1,len(yVector)))\n",
    "    theta = np.ones((Digits.columns[-1]+1))*0.0001\n",
    "    for i in range(1,Digits.columns[-1]):\n",
    "        xMatrix[i] = Digits[i]\n",
    "        \n",
    "    thetaMatrix, yMatrix = splitClasses(theta, yVector)\n",
    "    \n",
    "    costs = [[]]\n",
    "    for i in range(len(yMatrix)):\n",
    "        costs[0].append(costLogFunction(thetaMatrix[i], xMatrix.T, yMatrix[i], Lambda))\n",
    "    #print \"Old costs: \", costs[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        costs.append([])\n",
    "        for j in range(len(yMatrix)):\n",
    "            thetaMatrix[j] = updateLog(alpha, thetaMatrix[j], xMatrix, yMatrix[j], Lambda)\n",
    "            costs[i+1].append(costLogFunction(thetaMatrix[j], xMatrix.T, yMatrix[j], Lambda))\n",
    "    \n",
    "    #print \"New cost: \", costs[-1]\n",
    "    costs = np.array(costs).T\n",
    "    x = np.arange(0,len(costs[0]))\n",
    "    '''\n",
    "    plt.plot(x,costs[0])\n",
    "    plt.plot(x,costs[1], 'r')\n",
    "    plt.plot(x,costs[2], 'g')\n",
    "    plt.show()\n",
    "    '''\n",
    "    return thetaMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initTestData(Digits):\n",
    "    yVector = Digits[Digits.columns[-1]]\n",
    "    xMatrix = np.ones((Digits.columns[-1]+1,len(yVector)))\n",
    "    classes = list(set(yVector))\n",
    "    yMatrix = np.zeros((len(yVector),len(classes)))\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(yVector)):\n",
    "            if yVector[j] == classes[i]:\n",
    "                yMatrix[j][i] = 1\n",
    "            else:\n",
    "                yMatrix[j][i] = 0\n",
    "    yMatrix = yMatrix.T\n",
    "    return xMatrix, yMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracyMeasure(theta, xMatrix, yVector):\n",
    "    score = 0\n",
    "    for i in range(len(yVector)):\n",
    "        prediction = -math.log(hypothesis(theta,xMatrix[i]))\n",
    "        if prediction > 0.5 and yVector[i] == 1:\n",
    "            score +=1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "240\n",
      "240\n",
      "Accuracy of logistic regression in percentage:  100.0\n",
      "Accuracy of naive Bayes in percentages:  98.6666666667\n"
     ]
    }
   ],
   "source": [
    "# Compare logistic regression an naive Bayes\n",
    "\n",
    "Lambda = 10\n",
    "logregThetaMatrix = logreg(Training, Lambda)\n",
    "xMatrix, yMatrix = initTestData(Test)\n",
    "score = 0\n",
    "for i in range(len(yMatrix)):\n",
    "    score += accuracyMeasure(logregThetaMatrix[i], xMatrix.T, yMatrix[i])\n",
    "\n",
    "print \"Accuracy of logistic regression in percentage: \", score/len(yMatrix[0])*100.0\n",
    "\n",
    "classDict = makeClassDict(TrainingNpArray)\n",
    "\n",
    "allClasses = meanStdAll(classDict)\n",
    "\n",
    "predicts = getPredictions(allClasses, TrainingNpArray[:,:-1])\n",
    "\n",
    "print \"Accuracy of naive Bayes in percentages: \", accuracy(predicts, TrainingNpArray[:,-1])*100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discussion\n",
    "\n",
    "As shown above the percentages of both classifiers are quite high, the logistic regression even scores 100 percent.\n",
    "So the logistic regression is slightly better."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
